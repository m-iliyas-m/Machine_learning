{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "206e41fa-bfd8-42b8-9018-7c253ea548ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "import cv2 \n",
    "import time \n",
    "import mediapipe as mp\n",
    "import math\n",
    "import vlc\n",
    "import os\n",
    "from ctypes import cast, POINTER\n",
    "from comtypes import CLSCTX_ALL\n",
    "from pycaw.pycaw import AudioUtilities, IAudioEndpointVolume\n",
    "import numpy as np\n",
    "\n",
    "devices = AudioUtilities.GetSpeakers()\n",
    "interface = devices.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "volume = cast(interface, POINTER(IAudioEndpointVolume))\n",
    "vRange = volume.GetVolumeRange()\n",
    "volper = 0  \n",
    "minV = vRange[0]\n",
    "maxV = vRange[1] \n",
    "media = vlc.MediaPlayer(\"fukrey 3.mkv\")\n",
    "media.play()\n",
    "\n",
    "wCam,hCam = 670,480\n",
    "vol = 0\n",
    "volbar = 350\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(3,wCam)\n",
    "cap.set(4,hCam)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    min_detection_confidence=0.8,\n",
    "    min_tracking_confidence=0.5) as hands:\n",
    "    pause_flag = True\n",
    "    thumbs_up_flag = False\n",
    "    start_time = 0\n",
    "    skip_forward_flag = False\n",
    "    thumb_up_triggered = False\n",
    "\n",
    "    while(True):\n",
    "        success, img = cap.read()\n",
    "    \n",
    "        img = cv2.cvtColor(cv2.flip(img, 1), cv2.COLOR_BGR2RGB)\n",
    "        img.flags.writeable = False\n",
    "        results = hands.process(img)\n",
    "\n",
    "        img.flags.writeable = True\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        cv2.rectangle(img,(380,75),(630,350),(153, 255, 204),1)\n",
    "        x_roi1,y_roi1 = 380,75\n",
    "        x_roi2,y_roi2 = 630,350\n",
    "        \n",
    "        cv2.rectangle(img,(125,75),(225,350),(153, 255, 204),1)\n",
    "        x_roi3,y_roi3 = 125,75\n",
    "        x_roi4,y_roi4 = 225,350\n",
    "        \n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(img, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "            x11,y11 = int(hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].x*wCam) ,int(hand_landmarks.landmark[mp_hands.HandLandmark.PINKY_TIP].y* hCam) \n",
    "            x10,y10 = int(hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x*wCam),int(hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y* hCam)\n",
    "\n",
    "            if (x_roi1<x10) and (x11<x_roi2):\n",
    "                cv2.putText(img,'Play/Pause controller',(355,50),cv2.FONT_HERSHEY_COMPLEX,0.7,(26, 26, 26),2)\n",
    "                x3,y3 = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x*wCam) ,int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y* hCam) \n",
    "                x4,y4 = int(hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].x*wCam),int(hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y* hCam)\n",
    "\n",
    "                cv2.line(img,(x3,y3),(x4,y4),(159, 226, 191),3)\n",
    "\n",
    "                length1 = math.hypot(x3-x4,y3-y4)\n",
    "\n",
    "                #pause 75-90\n",
    "                #play > 150\n",
    "\n",
    "                if length1>200 and pause_flag == False:\n",
    "                    pause_flag = True\n",
    "                    media.play()\n",
    "                    cv2.putText(img,'Play ',(390,150),cv2.FONT_HERSHEY_COMPLEX,0.7,(26, 26, 26),2)\n",
    "                elif length1<110 and pause_flag == True:\n",
    "                    pause_flag = False\n",
    "                    media.pause()\n",
    "                    cv2.putText(img,'Pause',(390,150),cv2.FONT_HERSHEY_COMPLEX,0.7,(26, 26, 26),2)\n",
    "\n",
    "            elif (x_roi3<x10) and (x11<x_roi4):\n",
    "\n",
    "                cv2.putText(img,'Volume controller',(125,50),cv2.FONT_HERSHEY_COMPLEX,0.7,(26, 26, 26),2)\n",
    "                x1,y1 = int(hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x*wCam) ,int(hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y* hCam) \n",
    "                x2,y2 = int(hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].x*wCam),int(hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y* hCam)\n",
    "                cx = int((x1+x2)/2)\n",
    "                cy = int((y1+y2)/2)\n",
    "\n",
    "                cv2.circle(img,(x1,y1),15,(204, 204, 255),cv2.FILLED)\n",
    "                cv2.circle(img,(x2,y2),15,(204, 204, 255),cv2.FILLED)\n",
    "                cv2.circle(img,(cx,cy),15,(204, 204, 255),cv2.FILLED)\n",
    "\n",
    "                cv2.line(img,(x1,y1),(x2,y2),(159, 226, 191),3)\n",
    "\n",
    "                length = math.hypot(x2-x1,y2-y1)\n",
    "                #print(length)\n",
    "\n",
    "                if length<30:\n",
    "                    cv2.circle(img,(cx,cy),15,(0,255,0),cv2.FILLED)\n",
    "\n",
    "                #hand range = 30-200\n",
    "                #vol range = -65 - 0\n",
    "\n",
    "                vol = np.interp(length,[30,200],[minV,maxV])\n",
    "                volbar = np.interp(length,[30,200],[350,100])\n",
    "                volper = np.interp(length,[30,200],[0,100])\n",
    "                #print(vol)\n",
    "                volume.SetMasterVolumeLevel(vol,None)\n",
    "             # Forward/Rewind Control\n",
    "            # if not thumb_up_triggered:\n",
    "            #     # Thumbs up gesture\n",
    "            #     if (\n",
    "            #         hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y\n",
    "            #         < hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP].y\n",
    "            #         and hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y\n",
    "            #         < hand_landmarks.landmark[mp_hands.HandLandmark.MIDDLE_FINGER_TIP].y\n",
    "            #     ):\n",
    "            #         thumb_up_triggered = True\n",
    "            #         media.pause()\n",
    "            #         media.set_time(media.get_time() + 30 * 1000)  # Forward 30 seconds\n",
    "            #         cv2.putText(\n",
    "            #             img,\n",
    "            #             'Forward 30s',\n",
    "            #             (390, 200),\n",
    "            #             cv2.FONT_HERSHEY_COMPLEX,\n",
    "            #             0.7,\n",
    "            #             (26, 26, 26),\n",
    "            #             2,\n",
    "            #         )\n",
    "\n",
    "            cv2.rectangle(img,(50,100),(85,350),(153, 204, 255),3)\n",
    "            cv2.rectangle(img,(50,int(volbar)),(85,350),(102, 255, 255),cv2.FILLED)\n",
    "            cv2.putText(img,f'{int(volper)}%',(40,50),cv2.FONT_HERSHEY_COMPLEX,0.7,(26, 26, 26),2)\n",
    "\n",
    "            # # Gesture for skipping forward by 30 seconds (Thumbs Up)\n",
    "            # if results.multi_hand_landmarks:\n",
    "            #     for hand_landmarks in results.multi_hand_landmarks:\n",
    "            #         x12, y12 = int(hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].x * wCam), int(\n",
    "            #             hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP].y * hCam)\n",
    "            #         x9, y9 = int(hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].x * wCam), int(\n",
    "            #             hand_landmarks.landmark[mp_hands.HandLandmark.WRIST].y * hCam)\n",
    "                    \n",
    "            #         if y12 < y9:\n",
    "            #             if not skip_forward_flag:\n",
    "            #                 start_time = time.time()\n",
    "            #                 skip_forward_flag = True\n",
    "            #             else:\n",
    "            #                 current_time = time.time()\n",
    "            #                 elapsed_time = current_time - start_time\n",
    "            #                 if elapsed_time >= 2:  # Adjust this time as needed\n",
    "            #                     # Skip forward by 30 seconds\n",
    "            #                     media.set_time(media.get_time() + 30000)\n",
    "            #                     skip_forward_flag = False\n",
    "            #         else:\n",
    "            #             skip_forward_flag = False\n",
    "        cv2.imshow('HAND GESTURE RECOGNITION', img)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            media.stop()\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5160c38-a03d-421a-b960-32e897846901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a156a85b-2a60-4023-9133-ad33a0e1a9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
